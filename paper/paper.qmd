---
title: "Lower tax brackets and employment levels, and people living in populous areas are more likely to vote for Biden"
author: 
  - Victor Ma
thanks: "Code and data are available at: https://github.com/bestmustard/political_support"
date: 12/3/2024
date-format: long
abstract: "In this study, I investigate demographic patterns that influence political support during the 2020 U.S. Presidential Election, focusing on whether socio-economic factors like employment status, income level, and living environment influence voters' likelihood to support Joe Biden or Donald Trump. I employ a logistic regression model to analyze these predictors and identify trends within each demographic category. The results show that urban residents, lower-income groups, and individuals in specific employment categories (e.g., students and retirees) are more likely to support Joe Biden. These findings align with broader trends in U.S. politics, where socio-economic conditions and regional contexts play pivotal roles in shaping political preferences."
format: pdf
number-sections: true
bibliography: references.bib
editor: 
  markdown: 
    wrap: 72
    
header-includes:
 \usepackage{float}
 \floatplacement{figure}{H}
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(dataverse)
library(knitr)
library(modelsummary)
library(rstanarm)
library(tidybayes)
library(dplyr)
library(patchwork)
library(ggplot2)
library(broom.mixed)
library(GGally)

cleaned_data <- read_csv("../data/02-analysis_data/analysis_data.csv")
```

# Introduction
The 2020 United States presidential election highlighted societal shifts during crises. The COVID-19 pandemic reshaped healthcare and exposed systemic vulnerabilities, while economic inequality became central as unemployment surged [@Blustein2020; @BLS2020]. Climate change also emerged as a priority, driven by natural disasters [@IPCC2020].

Demographic patterns influenced the election. Younger, diverse voters emphasized generational and racial divides in priorities [@Frey2020]. Suburban voting patterns among college-educated women revealed shifts in key areas [@Cook2020]. Mail-in voting increased accessibility during the pandemic but fueled debates over election integrity [@NCSL2020]. The election tested democratic institutions against misinformation and polarization [@BenGurion2020; @Sunstein2020].

Living environments strongly shaped political alignment. Urban residents predominantly supported Joe Biden, reflecting progressive policy preferences [@bishop2019bigsort]. Rural voters favored Donald Trump, consistent with conservative values [@cramer2016politics]. Employment status and income further defined political divides. Students and retirees leaned toward Biden, driven by concerns about healthcare and education [@cces2020]. Higher-income voters leaned Republican, especially in rural and suburban areas [@pew2020voteranalysis].

This study estimates the probability of voting for Joe Biden versus Donald Trump, conditional on living environment, employment status, and income levels. Logistic regression, suited for binary outcomes, is used to model these relationships. The analysis relies on the 2020 Cooperative Congressional Election Study (CCES), a stratified survey conducted by YouGov and sourced from the Harvard Dataverse [@cces2020]. Supporting data from Pew Research and the Census Bureau’s Current Population Survey validate findings [@pew2020; @CPS2020].

The estimand is the probability that a voter supports Joe Biden as opposed to Donald Trump, conditional on the socio-economic factors of living environment, employment status, and income levels.

The report includes five sections and an appendix. After the introduction, the first section describes the CCES dataset, highlighting demographic distributions. The second section explains the logistic regression model and presents findings. The third section analyzes the effects of living environment, employment, and income on voting using visualizations and numerical results. The fourth section discusses implications, limitations, and directions for future research.

The appendix explores survey methodologies, focusing on sampling and observational data in the CCES dataset. It compares methodologies and discusses sampling variability and biases.

This analysis was conducted in R, using tidyverse for data manipulation, dataverse for dataset access, knitr for report generation, modelsummary for model interpretation, and rstanarm for Bayesian regression [@citeR; @Dataverse; @Knitr; @Modelsummary; @Rstanarm; @Tidybayes; @Dplyr]. Visualizations were created with ggplot, and portions of the discussion and appendix were assisted by ChatGPT4 [@chatgpt].
\newpage


# Data
The dataset for this analysis is the 2020 Cooperative Election Study (CCES) [@ces2020], accessed via the Harvard Dataverse. The 2020 iteration surveyed 61,000 respondents, capturing a broad range of U.S. political opinions. The release includes detailed documentation and questionnaires, ensuring transparency and replicability. Vote validation was conducted by Catalist, a large-scale organization maintaining data on over 240 million U.S. individuals [@Catalist2017].

## Strengths

### Sample Size

Sources for @fig-respondents below: [@ANES2020],[@Pew2020],[@Edison2020], [@ces2020].

```{r out.height="30%"}
#| label: fig-respondents
#| fig-cap: "Number of respondents for various 2020 election survey sources"
#| echo: false
#| warning: false
#| message: false

# Create a data frame with the number of respondents for each source
survey_data <- data.frame(
  Source = c("ANES 2020", "Pew Research", "Edison Exit Polls", "CCES 2020"),
  Respondents = c(8280, 11818, 25000, 61000) # Updated with additional sources
)

# Generate the bar graph
ggplot(survey_data, aes(x = Source, y = Respondents, fill = Source)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(
    title = "Number of Respondents per Survey Source",
    x = "Survey Source",
    y = "Respondents"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Angle the x-axis text for readability

```


@fig-respondents shows that CCES poll features the largest respondent pool compared to other surveys. This extensive sample size enables granular analyses, ensuring the representation of smaller subgroups that may be underrepresented in smaller datasets [@Ansolabehere2020].

### Data Collection Phases
The CCES collected data in two waves, immediately before and after the 2020 election. This helps capture the shifts in voter attitudes and preferences during the final stages of the election campaign [@ces2020]. Pew Research and Gallup each conduct multiple polls of much smaller scale leading up to the election, which will give a snapshot in time of the voter sentiment but does not capture a longitudinal perspective similarly to the CES survey [@Pew2020].

### Sampling Methodology
The CCES employs a two-step sample matching methodology designed to create a representative survey sample:

#### Target Sample Creation
A target sample is generated to reflect the broader population based on key demographic variables such as age, gender, race, and educational attainment. This target sample serves as a benchmark for representativeness.

#### Matched Sample Selection
For each individual in the target sample, a closely matched respondent is selected from a pool of survey volunteers maintained by YouGov. Matches are determined using a combination of publicly available databases and YouGov’s proprietary data, ensuring close alignment on variables such as geography, party registration, and voter history.

Once the matched sample is established, it is weighted to adjust for discrepancies between the sample and the target population. The weighting process involves two stages:

#### Demographic Weighting
Adjustments are made using data from the American Community Survey to ensure accurate representation across demographics.

#### Voting Behavior Weighting
Further adjustments incorporate validated voter registration data, accounting for turnout and voting patterns at the state and national levels.

Validation of the sampling methodology is conducted by comparing state-level survey results with official election outcomes. This comparison ensures that survey estimates align with actual voter behavior, providing confidence in the dataset's representativeness.

The sampling approach is specifically designed for online opt-in panels and mitigates biases commonly associated with such surveys, such as overrepresentation of politically engaged respondents. Unlike traditional random or quota sampling, this methodology emphasizes precision in matching and post-stratification to minimize systematic error [@ces2020], [@sample2007].

## Limitations
The data has some limitations. An error affected 925 North Carolina respondents who were shown incorrect House race candidates, impacting analyses of these districts. Additionally, self-reported data can introduce biases such as recall or social desirability bias. Pre-election surveys may also fail to capture last-minute shifts in voter sentiment.

The online nature of the survey, hosted by YouGov, expands accessibility but may underrepresent groups with limited internet access or technological literacy. Furthermore, the lack of an interviewer in online surveys could impact response quality [@ces2020].

## Variables of Interest
The selection of living environment, employment status, and income level as predictor variables for analyzing political preferences in the 2020 CCES data is guided by prior research that shows their influence on voting behavior.

### Urban vs. Rural Residency
Urban and rural divides are well-documented predictors of political preferences. Urban voters have consistently leaned Democratic, driven by higher population density and exposure to diverse cultural and socioeconomic dynamics. For example, Pew Research found that 62% of urban voters supported Hillary Clinton in the 2016 election, compared to only 35% in rural areas [@Pew2018]. Rural voters, in contrast, exhibit stronger support for Republican candidates, influenced by traditional values and economic concerns rooted in agriculture and resource-based industries [@Cramer2016].

Research also shows that suburban areas, often politically contested, have shifted in recent years. The Cook Political Report highlights a notable swing in suburban support toward Democratic candidates in 2020, attributed to changes in demographics and education levels among suburban voters [@Cook2020].

### Income Level
Income levels are closely tied to political preferences, with higher-income individuals generally favoring Republican candidates due to tax policies, while lower-income groups often lean Democratic, prioritizing social welfare and redistribution policies [@Frank2004]. For example, the Census Bureau's Current Population Survey shows that in 2020, households earning under $50,000 were more likely to support Joe Biden, while those earning over $100,000 favored Donald Trump [@CPS2020].

However, this trend is affected by education levels and geographic factors. High-income earners in urban areas often prioritize social liberalism and climate change policies, aligning with Democratic platforms, while rural high-income earners focus more on fiscal conservatism [@Pew2020; @Edsall2020].

### Employment Level
Employment status significantly impacts voter preferences, with distinct patterns emerging across different occupational categories. Full-time workers are often divided along industry lines, with white-collar employees tending to support Democratic candidates and blue-collar workers aligning more with Republican candidates [@Muro2020]. Unemployment during economic crises, such as the COVID-19 pandemic, has further shaped voting patterns. Studies show that unemployed individuals are more likely to support candidates promising expansive social safety nets and job creation [@Blustein2020; @Fowler2020].

Retirees also exhibit unique voting behaviors, often prioritizing stability and healthcare, leading to a higher likelihood of Republican support [@KFF2020]. In contrast, students, who are less economically established and more progressive, tend to favor Democratic candidates [@Frey2020].

## Data Preparation and Cleaning
The 2020 CCES data, as recorded by Schaffner, Brian et al., was obtained from the Harvard Dataverse and processed using the arrow package for efficient storage in parquet format [@arrow]. The raw data was imported from a CSV file, and the cleaning process involved filtering for registered voters who cast votes for either Joe Biden or Donald Trump, treating the presidential vote as a binary outcome.

Key variables were transformed for clarity and analysis:

Living Environment: Categorized into "City," "Suburb," "Town," and "Rural area" based on the urbancity variable.
Employment Status: Labeled as "Full-time," "Part-time," "Temporarily laid off," "Unemployed," "Retired," "Permanently disabled," "Homemaker," or "Student."
Income Levels: Grouped into ranges: "< 10k," "10-50k," "50-100k," "100-200k," "200-500k," and "> 500k."
These transformations were implemented using the dplyr package for data manipulation. Each variable was converted into a factor with ordered levels to facilitate analysis and visualization.

The cleaned dataset was saved in both CSV and parquet formats for ease of use in subsequent analyses. Distributions for key explanatory variables, such as living environment, employment status, and income, are visualized in @fig-living, @fig-employment, and @fig-income below.

```{r out.height="20%"}
#| label: fig-living
#| fig-cap: "Number of respondents by area of living"
#| echo: false
#| warning: false
#| message: false

# Plot for area of living, excluding NA values
ggplot(cleaned_data %>% filter(!is.na(living)), aes(x = living)) +
  geom_bar(fill = "#87CEEB") +
  theme_minimal() +
  labs(title = "Respondents per Area of Living",
       x = "Living Environment",
       y = "Count") +
  theme(legend.title = element_blank(),
        plot.title = element_text(size = 14))

```
```{r out.height="20%"}
#| label: fig-employment
#| fig-cap: "Number of respondents by employment status"
#| echo: false
#| warning: false
#| message: false

# Plot for employment status
ggplot(cleaned_data %>% filter(!is.na(employment)), aes(x = employment)) +
  coord_flip() +
  geom_bar(fill = "#87CEFA") +
  theme_minimal() +
  labs(title = "Respondents per Employment Status",
       x = "Employment Status",
       y = "Count") +
  theme(legend.title = element_blank(),
        plot.title = element_text(size = 14))

```
```{r out.height="20%"}
#| label: fig-income
#| fig-cap: "Number of respondents by family income level"
#| echo: false
#| warning: false
#| message: false

# Plot for income level, excluding NA values
ggplot(cleaned_data %>% filter(!is.na(income)), aes(x = income)) +
  geom_bar(fill = "#FFD700") +
  theme_minimal() +
  labs(title = "Respondents per Income Level",
       x = "Income Level",
       y = "Count") +
  theme(legend.title = element_blank(),
        plot.title = element_text(size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels for clarity
```
@fig-living shows that the most common respondents were living in the suburbs and the city. 

In @fig-employment, the most common employment levels were full-time employees or retired.

@fig-income shows that the most common income levels were between the 10-100k range, and there was a high number of participants with an income level above $500,000.

```{r out.height="30%"}
#| label: fig-scatter-income-employment
#| fig-cap: "Income vs. Employment Status"
#| echo: false
#| warning: false
#| message: false

ggplot(cleaned_data, aes(x = employment, y = as.numeric(income), color = voted_for)) +
  geom_jitter(width = 0.2, height = 0) +
  scale_color_brewer(palette = "Set2") +
  theme_minimal() +
  labs(
    title = "Income vs. Employment Status",
    x = "Employment Status",
    y = "Income Level",
    color = "Voted For"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1) # Slant x-axis text
  )

```

@fig-scatter-income-employment shows us the income distribution across employment types.

Full-time workers exhibit the widest income distribution, spanning from "<10k" to ">500k."
Retirees and students predominantly occupy lower income levels, aligning with expectations based on fixed or limited income sources.

Retirees and students show a strong preference for Biden, while higher-income full-time workers lean slightly toward Trump.
Homemakers and permanently disabled individuals display narrower income ranges but include both Biden and Trump voters.

In the ">500k" category, Trump garners more support, consistent with Republican tax policies favoring high-income earners.
These patterns underscore the relationships between employment, income, and political preferences, highlighting the diversity of economic profiles within voter bases.

```{r out.height="30%"}
#| label: fig-heatmap-employment-living
#| fig-cap: "Heatmap of employment status and living environment"
#| echo: false
#| warning: false
#| message: false

# Pre-compute counts for the heatmap
heatmap_data <- cleaned_data %>%
  count(living, employment)

# Create the heatmap
ggplot(heatmap_data, aes(x = living, y = employment, fill = n)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "blue") +
  theme_minimal() +
  labs(title = "Employment Status by Living Environment",
       x = "Living Environment",
       y = "Employment Status",
       fill = "Count")
```

The @fig-heatmap-employment-living shows the distribution of employment statuses across different living environments:

Suburbs have the highest concentration of full-time workers, as indicated by the deep blue color. This aligns with the demographic trends of suburban areas, which often attract working professionals due to proximity to urban centers and family-friendly amenities.

Retirees are present in all living environments, with notable concentrations in both suburbs and rural areas. This reflects retirement trends where individuals seek quieter or more affordable living conditions outside cities.

Rural areas show a higher proportion of homemakers compared to other environments, consistent with traditional family roles in less urbanized areas.

Cities have the largest concentration of students, likely due to the presence of educational institutions and urban amenities.

Rural areas show higher proportions of unemployed and permanently disabled individuals compared to cities and suburbs, highlighting economic disparities and limited job opportunities in these regions.

Part-time work and temporary layoffs are distributed fairly evenly across living environments, suggesting they are less influenced by geographic location.

```{r out.height="20%"}
#| label: fig-incomevotes
#| fig-cap: "Votes for Biden at each level of income"
#| echo: false
#| warning: false
#| message: false

#### Generate income_summary ####
income_summary <- cleaned_data %>%
  group_by(income) %>%
  summarize(
    proportion_biden = mean(voted_for == "Biden", na.rm = TRUE),
    total_count = n()
  )

#### Correcting the order of income levels ####
income_summary <- income_summary |> 
  mutate(
    income = factor(
      income,
      levels = c("< 10k", "10-50k", "50-100k", "100-200k", "200-500k", "> 500k")
    )
  )

#### Create the corrected point plot ####
ggplot(income_summary, aes(x = income, y = proportion_biden)) +
  geom_point(size = 3, color = "blue") + # Plot points only
  theme_minimal() +
  labs(
    title = "Proportion of Votes for Biden by Income Level",
    x = "Income Level",
    y = "Proportion Voting for Biden"
  ) +
  scale_y_continuous(labels = scales::percent_format()) # Display y-axis as percentages


```

@fig-incomevotes shows that income level does not seem to have a correlation with voting for Biden.

```{r out.height="20%"}
#| label: fig-employmentvotes
#| fig-cap: "Votes for Biden at each employment level"
#| echo: false
#| warning: false
#| message: false

#### Calculate proportions for employment ####
employment_summary <- cleaned_data |>
  group_by(employment) |>
  summarize(
    proportion_biden = mean(voted_for == "Biden"),
    .groups = "drop"
  )

#### Create point plot for employment ####
ggplot(employment_summary, aes(x = employment, y = proportion_biden)) +
  geom_point(size = 3, color = "blue") +
  theme_minimal() +
  labs(
    title = "Proportion of Votes for Biden by Employment Status",
    x = "Employment Status",
    y = "Proportion Voting for Biden"
  ) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Optional: Rotate x-axis labels

```
@fig-employmentvotes shows that the greatest number of voters for Biden were Students, and it seems to decrease with higher employment levels. However, all categories still favor Biden.

```{r out.height="20%"}
#| label: fig-livingvotes
#| fig-cap: "Votes for Biden based on residency"
#| echo: false
#| warning: false
#| message: false

#### Calculate proportions for living area ####
living_summary <- cleaned_data |>
  group_by(living) |>
  summarize(
    proportion_biden = mean(voted_for == "Biden"),
    .groups = "drop"
  )

#### Create point plot for living area ####
ggplot(living_summary, aes(x = living, y = proportion_biden)) +
  geom_point(size = 3, color = "blue") +
  theme_minimal() +
  labs(
    title = "Proportion of Votes for Biden by Living Area",
    x = "Living Area",
    y = "Proportion Voting for Biden"
  ) +
  scale_y_continuous(labels = scales::percent_format()) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Optional: Rotate x-axis labels

```

@fig-livingvotes shows a direct correlation between the density of peoples' living area and their probability of voting for Biden. People in the city had a high chance of voting Biden, while rural is much lower.

# Model

This report presents a logistic regression model to predict whether a respondent voted for Joe Biden (1) or Donald Trump (0), based on their employment status, income level, and living environment. The analysis uses Bayesian logistic regression implemented in R with the rstanarm package. The model's performance is evaluated through various validation techniques, including train-test splits, posterior predictive checks, and sensitivity analyses.

For this analysis, the predictors are employment status, income level, and living environment. These variables are passed through the logistic function to estimate $P(Y_i=1)$, the probability that respondent $i$ votes for Joe Biden.

```{=tex}
\[ \sigma(t) = \frac{1}{1 + e^{-t}} \]
```
## Implementation

The model is implemented using R, using the rstanarm package for Bayesian logistic regression. The data was preprocessed using the tidyverse package. Model outputs and intermediate steps are saved in .rds format for reproducibility [@citeR, @Rstanarm]. The model was implemented using the stan_glm() function, which applies Bayesian logistic regression with default priors and estimates the $\beta$ coefficients for the predictors. The model was fit to a subset of 3000 respondents from the 2020 CCES data processed earlier.

## Model Specification

The logistic function produces an S-shaped sigmoid curve, which asymptotically approaches 1 as $t$ increases and 0 as $t$ decreases. In logistic regression, the input $t$ is modeled as a linear combination of predictors (including an intercept), expressed as $\beta_0 + \beta_1X_1 + \beta_2X_2 + \dots + \beta_nX_n$. This transforms the predictors into probabilities of the binary outcome.

The model is defined as:

```{=tex}
\[
\log\left(\frac{P(Y_i=1)}{1 - P(Y_i=1)}\right) = \beta_0 + \beta_1X_{\text{employment},i} + \beta_2X_{\text{income},i} + \beta_3X_{\text{living},i}
\]
```

$Y_i$: Binary response indicating vote for Biden (1) or Trump (0).

$X_{\text{employment},i}$: Employment status.

$X_{\text{income},i}$: Income level.

$X_{\text{living},i}$: Living environment.

$\beta_0$: Intercept term.

$\beta_1$, $\beta_2$, $\beta_3$: Coefficients for predictors.

The log-odds are transformed into probabilities using the logistic function:
```{=tex}

\[
P(Y_i=1) = \frac{1}{1 + e^{-t}}
\]
```

where $t = \beta_0 + \beta_1X_{\text{employment},i} + \beta_2X_{\text{income},i} + \beta_3X_{\text{living},i}$.

## Justification

Employment, income, and living environment are socio-economic factors that significantly influence voting preferences. These variables are categorical, making logistic regression suitable for analyzing their relationship with a binary outcome. The model avoids unnecessary complexity by focusing on these key variables while maintaining interpretability. Priors ($\beta_0, \beta_k \sim \text{Normal}(0, 2.5)$) are weakly informative, ensuring coefficients are regularized without constraining the model [@Gelman2008].

The dataset is split into 70% training and 30% test sets to validate out-of-sample performance. This ensures the model generalizes well to unseen data. The ROC (Receiver Operating Characteristic) curve is a graphical representation of the model's ability to distinguish between the two classes: votes for Biden (1) and Trump (0). It plots the true positive rate (sensitivity) against the false positive rate (1-specificity) at various threshold settings. The AUC (Area Under the Curve) quantifies the overall ability of the model to discriminate between the classes. An AUC of 1.0 indicates perfect discrimination, while 0.5 indicates no better performance than random guessing.

Posterior predictive checks ensure the model fits the data well by comparing simulated outcomes to observed data. This helps evaluate whether the model appropriately represents the underlying data distribution. The residual histogram shows the distribution of residuals, representing the differences between observed and predicted values. The residuals are distributed symmetrically around zero, which suggests that the model does not exhibit significant bias in its predictions. The histogram shows two peaks, one slightly negative and the other slightly positive. This may indicate that the model performs differently for different subsets of the data (e.g., voters for Biden vs. Trump). This could reflect the nature of binary logistic regression, where predictions are pushed toward 0 or 1. The spread of residuals is relatively narrow, with most values falling between -0.5 and 0.5. This suggests that the model's predictions are not overly far from the observed values.

Underlying assumptions include the linearity of predictors on the log-odds scale, independence of observations, and the assumption that predictors adequately capture variability in the data. Limitations include the categorical nature of the predictors, which may lose granularity, and the potential omission of confounders such as race or education level. The model may be less appropriate in cases where relationships are non-linear or involve strong interaction effects. Alternatives considered include random forests, which are more flexible but lack interpretability, and multinomial logistic regression, which was unnecessary for this binary outcome. Logistic regression was chosen for its balance of simplicity, interpretability, and compatibility with the data structure.

The validation process includes a train-test split to ensure generalization to new data, ROC Curve and AUC to demonstrate the model's discrimination ability with a moderate AUC value, posterior predictive checks to validate that simulated outcomes align well with observed data, and residual analysis to confirm model assumptions and identify any misfit. These steps confirm the reliability of the logistic regression model for this use case.

# Results

The resuls of this analysis show that employment, income, and living environment significantly influence political alignment. The coefficients in @tbl-model_summary display the impact of each predictor on the likelihood of voting for Joe Biden versus Donald Trump.

```{r}
#| label: tbl-model_summary
#| tbl-cap: "Coefficient Summary of the Logistic Regression Model"
#| echo: false
#| warning: false
#| message: false
political_preferences <- readRDS(file ="../models/political_preferences.rds")

# Extract coefficients and statistics into a data frame
model_summary_df <- broom::tidy(political_preferences, conf.int = TRUE) %>%
  dplyr::select(term, estimate, std.error, conf.low, conf.high) %>%
  dplyr::rename(
    Parameter = term,
    Mean = estimate,
    `Standard Error` = std.error,
    `Lower 95% CI` = conf.low,
    `Upper 95% CI` = conf.high
  )

# Use kable to format the summary table
kable(model_summary_df, format = "markdown", align = "c", col.names = c("Parameter", "Mean", "Standard Error", "Lower 95% CI", "Upper 95% CI"))

```

The intercept shows the baseline log-odds of voting for Biden when all predictors are at their reference level (e.g., baseline employment group, income group, and living environment).

### Employment

Positive coefficients (e.g., employmentStudent) indicate that being in this group increases the likelihood of voting for Biden compared to the reference group (employmentFull-time).

Negative coefficients (e.g., employmentTemporarily laid off) suggest a decreased likelihood of voting for Biden compared to the reference group.

### Income

Lower-income groups (e.g., income10-50k) have negative coefficients, suggesting these groups are less likely to vote for Biden compared to the reference category (income <10k).

Higher-income groups (e.g., income>500k) also show decreased likelihood of voting for Biden, suggesting a possible U-shaped relationship between income and voting preference.

### Living Environment

Urban areas (livingCity, as reference) show the highest likelihood of voting for Biden. Suburbs and rural areas (livingSuburb, livingRural area) exhibit progressively stronger negative coefficients, indicating lower support for Biden.

### Confidence Intervals

The columns Lower 95% CI and Upper 95% CI show the range within which the true coefficient is likely to fall with 95% confidence. If this range does not include zero, the effect is statistically significant.

```{r}
#| label: fig-coefficient_intervals
#| fig-cap: "90% Credible Intervals for Logistic Regression Coefficients"
#| echo: false
#| message: false
#| warning: false

library(bayesplot)
posterior <- as.array(political_preferences)
color_scheme_set("brightblue")

mcmc_intervals(posterior, prob = 0.9) +
  labs(
    title = "Coefficient Estimates",
    subtitle = "90% Credible Intervals",
    x = "Coefficient Value",
    y = "Predictors"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )
```
The visualization in @fig-coefficient_intervals shows the 90% credible intervals for each predictor. Predictors with intervals that do not overlap zero indicate significant effects on voting preferences. For example, livingRural area exhibits a significant negative association with voting for Biden, while employmentStudent shows a strong positive effect.

## Model Results

The below bar graphs display the predicted support for different demographics with the other ones kept constant, with the green point showing the actual results as shown in @fig-incomevotes. 

```{r out.height="20%"}
#| label: fig-income-overlay
#| fig-cap: "Model Prediction vs. Actual Votes by Income Level"
#| echo: false
#| warning: false
#| message: false

#### Prediction data for income ####
prediction_data <- tibble(
  employment = "Full-time", # Keeping employment constant
  living = "City",          # Keeping living location constant
  income = factor(
    c("< 10k", "10-50k", "50-100k", "100-200k", "200-500k", "> 500k"),
    levels = c("< 10k", "10-50k", "50-100k", "100-200k", "200-500k", "> 500k")
  )
)

# Predict probabilities
predicted_probs_income <- posterior_epred(political_preferences, newdata = prediction_data) |>
  colMeans()

# Add predictions and odds
prediction_data <- prediction_data |> 
  mutate(
    predicted_prob = predicted_probs_income,
    odds = predicted_prob / (1 - predicted_prob)
  )

#### Calculate actual proportions ####
actual_income <- cleaned_data |>
  group_by(income) |>
  summarize(
    proportion_biden = mean(voted_for == "Biden"),
    .groups = "drop"
  )

#### Combine actual and predicted data ####
combined_income_data <- prediction_data |> 
  left_join(actual_income, by = "income") |> 
  mutate(
    actual_odds = proportion_biden / (1 - proportion_biden) # Convert proportions to odds
  )

#### Overlayed Plot ####
ggplot(combined_income_data) +
  geom_bar(aes(x = income, y = odds), stat = "identity", fill = "steelblue", alpha = 0.6) + # Predicted odds
  geom_point(aes(x = income, y = actual_odds), size = 3, color = "green") + # Actual odds
  labs(
    title = "Comparison of Predicted and Actual Support for Biden by Income Level",
    x = "Income Level",
    y = "Odds of Voting for Biden"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels


```

The predicted values in @fig-income-overlay are much lower likely due to the other demographics being set to "Full-time" and "City", but the trend in the results is the same.

```{r out.height="20%"}
#| label: fig-employment-overlay
#| fig-cap: "Model Prediction vs. Actual Votes by Employment"
#| echo: false
#| warning: false
#| message: false

#### Prediction data for employment ####
employment_data <- tibble(
  employment = factor(
    c("Full-time", "Part-time", "Temporarily laid off", "Unemployed", 
      "Retired", "Permanently disabled", "Homemaker", "Student"),
    levels = c("Full-time", "Part-time", "Temporarily laid off", "Unemployed", 
               "Retired", "Permanently disabled", "Homemaker", "Student")
  ),
  living = "City", # Keeping living constant
  income = "< 10k" # Keeping income constant
)

# Predict probabilities
predicted_probs_employment <- posterior_epred(political_preferences, newdata = employment_data) |>
  colMeans()

# Add predictions and odds
employment_data <- employment_data |> 
  mutate(
    predicted_prob = predicted_probs_employment,
    odds = predicted_prob / (1 - predicted_prob)
  )

#### Calculate actual proportions ####
actual_employment <- cleaned_data |>
  group_by(employment) |>
  summarize(
    proportion_biden = mean(voted_for == "Biden"),
    .groups = "drop"
  )

#### Combine actual and predicted data ####
combined_employment_data <- employment_data |> 
  left_join(actual_employment, by = "employment") |>
  mutate(
    actual_odds = proportion_biden / (1 - proportion_biden) # Convert proportions to odds
  )

#### Plot for comparison ####
ggplot(combined_employment_data) +
  geom_bar(aes(x = employment, y = odds), stat = "identity", fill = "steelblue", alpha = 0.6) + # Predicted odds
  geom_point(aes(x = employment, y = actual_odds), size = 3, color = "green") + # Actual odds
  labs(
    title = "Comparison of Predicted and Actual Odds of Voting for Biden by Employment Status",
    x = "Employment Status",
    y = "Odds of Voting for Biden"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

@fig-employment-overlay shows similarity in the general trend between the prediction and the actual data, with the exception of some of the middle values, where "Temporarily laid off" for example is lower than expected.

```{r out.height="20%"}
#| label: fig-living-overlay
#| fig-cap: "Model Prediction vs. Actual Votes by Living Area"
#| echo: false
#| warning: false
#| message: false

#### Load model ####

#### Prediction data ####
# Creating a dataset for prediction
prediction_data <- tibble(
  employment = "Full-time", # Keeping employment constant
  living = factor(
    c("City", "Suburb", "Town", "Rural area"),
    levels = c("City", "Suburb", "Town", "Rural area")
  ),
  income = "200-500k" # Keeping income constant
)

# Predict probabilities
predicted_probs <- posterior_epred(political_preferences, newdata = prediction_data) |>
  colMeans()

# Calculate odds
prediction_data <- prediction_data |> 
  mutate(
    predicted_prob = predicted_probs,
    odds = predicted_prob / (1 - predicted_prob) # Convert probabilities to odds
  )

#### Actual data for respondent counts ####
respondent_counts <- cleaned_data |> 
  group_by(living) |> 
  summarize(
    count = n(),
    .groups = "drop"
  )

#### Combine predicted and actual data ####
combined_living_data <- prediction_data |> 
  left_join(respondent_counts, by = "living")

# Calculate scaling factor
scaling_factor <- max(combined_living_data$count) / max(combined_living_data$odds)

#### Overlayed plot ####
ggplot(combined_living_data) +
  geom_bar(aes(x = living, y = count), stat = "identity", fill = "steelblue", alpha = 0.6) + # Respondent counts
  geom_point(aes(x = living, y = odds * scaling_factor), size = 3, color = "green") + # Scaled predicted odds
  scale_y_continuous(
    name = "Respondent Count",
    sec.axis = sec_axis(~ . / scaling_factor, name = "Odds of Voting for Biden")
  ) +
  labs(
    title = "Overlay of Predicted Odds and Respondent Counts by Living Area",
    x = "Living Area"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
@fig-living-overlay shows the model has completely different predictions for the living areas, when employment is set to "Full-time" and income is in the "200-500k" range. 

## Model Evaluation

The ROC (Receiver Operating Characteristic) curve is a graphical representation of the model's ability to distinguish between the two classes: votes for Biden (1) and Trump (0). It plots the true positive rate (sensitivity) against the false positive rate (1-specificity) at various threshold settings.

The AUC (Area Under the Curve) quantifies the overall ability of the model to discriminate between the classes. An AUC of 1.0 indicates perfect discrimination, while 0.5 indicates no better performance than random guessing.


```{r out.height="30%"}
#| label: fig-roc
#| fig-cap: "ROC Curve for logistic regression model"
#| echo: false
#| warning: false
#| message: false
#### Workspace setup ####
library(tidyverse)
library(rstanarm)

# Train-test split
set.seed(853)
train_indices <- sample(1:nrow(cleaned_data), 0.7 * nrow(cleaned_data))
train_data <- cleaned_data[train_indices, ]
test_data <- cleaned_data[-train_indices, ]

# Predictions on test data
test_predictions <- posterior_predict(political_preferences, newdata = test_data)

# ROC Curve and AUC
library(pROC)
roc_curve <- roc(test_data$voted_for, colMeans(test_predictions))
auc(roc_curve)

plot(roc_curve, main = "ROC Curve for Logistic Regression Model", col = "blue", lwd = 2)
```

The area under curve (AUC) value for the curve in @fig-roc is 0.6216. This indicates the model has moderate discriminatory power. It performs better than random guessing (AUC = 0.5) but falls short of strong predictive performance (AUC > 0.8).
This suggests the predictors (employment status, income, and living environment) have some explanatory power but may not fully capture voting behavior.

In terms of the shape of the curve, it deviates above the diagonal line (random chance), showing that the model can separate the two classes to some extent.

However, the relatively shallow curve implies the model struggles to achieve high sensitivity without sacrificing specificity.

The model is able to identify patterns in the data, distinguishing between Biden and Trump voters to a limited degree.
The AUC value indicates that important predictors influencing voting behavior may be missing (e.g., race, education, or political affiliation).

Further steps, such as feature engineering, adding interaction terms, or testing alternative models (e.g., random forests or support vector machines), may help enhance performance.

```{r out.height="30%"}
#| label: fig-pp
#| fig-cap: "ROC Curve for logistic regression model"
#| echo: false
#| warning: false
#| message: false
# Generating Posterior Predictive Plot
pp_check(political_preferences, plotfun = "dens_overlay") +
  ggtitle("Posterior Predictive Check")
```

In @fig-pp, The observed data $y$ is represented by the solid curve.
The replicated data $y_rep$ is represented by the shaded region, which covers the range of simulations based on the posterior distribution of the model parameters.

The replicated data closely follows the observed data curve between values 0.25-0.75, and diverges more at the extremes. This suggests that the model struggles to fully capture the extreme probabilities of voting for Biden or Trump.

The replicated data aligns more closely with the observed data in the middle of the probability range, indicating that the model performs better in areas of uncertainty where probabilities are closer to 50%.

The mismatch at the extremes suggests that the model may not be adequately capturing respondents with very high or very low likelihoods of voting for either candidate. This could indicate the need for additional predictors to account for factors driving extreme probabilities.

```{r out.height="30%"}
#| label: fig-residual
#| fig-cap: "ROC Curve for logistic regression model"
#| echo: false
#| warning: false
#| message: false
residuals <- residuals(political_preferences)
ggplot(data.frame(residuals), aes(x = residuals)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "black") +
  theme_minimal() +
  labs(title = "Histogram of Residuals", x = "Residuals", y = "Frequency")
```

@fig-residual shows the distribution of residuals, which represent the differences between observed and predicted values. The residuals are distributed symmetrically around zero, which suggests that the model does not exhibit significant bias in its predictions. The histogram shows two peaks, one slightly negative and the other slightly positive. This may indicate that the model performs differently for different subsets of the data (e.g., voters for Biden vs. Trump). This could reflect the nature of binary logistic regression, where predictions are pushed toward 0 or 1. The spread of residuals is relatively narrow, with most values falling between -0.5 and 0.5. This suggests that the model's predictions are not overly far from the observed values. The PPC confirms the model is reasonable for the given data but highlights areas for improvement, particularly at the extremes of the outcome probabilities. While the residuals and PPC suggest the model captures the data trends reasonably well, additional predictors or refinements, such as interactions, may be necessary to improve the fit for subsets of the data.

# Discussion

This paper examines how socio-economic factors—employment status, income level, and living environment—shape voting preferences in the 2020 U.S. Presidential Election. Using the 2020 Cooperative Election Study (CCES) dataset, a logistic regression model was applied to predict support for Joe Biden versus Donald Trump. The model incorporated categorical predictors to reflect socio-economic dimensions influencing voter behavior. Analysis identified relationships between these predictors and political alignment, highlighting socio-political dynamics in the United States.

The logistic regression model directly addressed the binary nature of the voting outcome, providing interpretable results on how each predictor influenced voting likelihood. Including categorical variables such as employment, income, and living environment allowed analysis of how socio-economic realities influence political preferences.

### Takeaways

The urban-rural divide continues to shape American politics. Urban voters predominantly supported Joe Biden, aligning with policies related to healthcare, environmental regulation, and equity [@Pew2020u]. Rural voters favored Donald Trump, supporting policies related to lower taxes, gun rights, and traditional values [@IyengarKrupenkin2018]. This polarization reflects growing differences between urban and rural constituencies.

Income also influenced voting behavior. Lower-income groups supported Biden, consistent with policies prioritizing social welfare and economic redistribution. Middle-income groups showed mixed preferences, balancing economic priorities with policy concerns. Higher-income voters leaned Republican, likely due to concerns over Democratic tax policies [@Frank2004; @Gelman2009]. These trends reflect a U-shaped relationship between income and political preferences.

Employment status further influenced voter behavior. Students and retirees supported Biden, reflecting priorities such as debt relief and Social Security. Full-time workers demonstrated varied preferences due to diverse priorities. Part-time and temporarily laid-off workers leaned toward Biden, likely reflecting concerns about job security and healthcare during the COVID-19 pandemic.

### Weaknesses

The model has several limitations. Logistic regression assumes linearity in log-odds, potentially oversimplifying relationships between predictors and voting behavior. Interaction effects, such as between income and employment, were not fully explored. 

Categorical predictors simplify analysis but reduce specificity. For instance, income ranges like "50-100k" include diverse experiences that may influence voting behavior differently. Employment categories exclude factors such as industry type or job stability, which likely play significant roles in voter preferences.

Reliance on self-reported survey data introduces biases like social desirability and recall errors [@Ansolabehere2012]. The cross-sectional nature of the CCES dataset limits the analysis to static preferences, ignoring changes over time and campaign effects [@Gelman2009]. Additionally, regional variations within urban and rural areas are not accounted for, which may obscure important differences.

### Future Directions

Future research could analyze how socio-economic factors interact with political events or social movements using longitudinal data, enabling causal analysis of voting behavior over time. Examining intersections of socio-economic factors with race, gender, or education could offer a richer understanding of voter preferences [@Highton2009].

Non-linear models and machine learning methods could uncover relationships missed by logistic regression. Decision tree-based models or neural networks could identify patterns in voter behavior, though they may sacrifice interpretability.

Regional analyses are necessary to understand how local economic and cultural contexts influence voting preferences. Comparing manufacturing-heavy states with service-oriented urban centers could refine explanations of socio-economic effects on voting.

This paper demonstrates the role of socio-economic factors in shaping political preferences. Addressing these limitations and pursuing these directions could deepen understanding of voter behavior and the socio-political landscape.

# Appendix: Survey and Sampling Methodology

### Overview of Survey Design in the CCES 2020 Dataset

The 2020 Cooperative Election Study (CCES) is a large-scale survey capturing U.S. political behavior and attitudes. Administered by YouGov with academic oversight, it uses stratified sampling to ensure national representation [@Ansolabehere2012]. The survey includes a pre-election wave in October 2020 and a post-election wave in November 2020, allowing comparisons of voter attitudes and behaviors during the election period. Data collection occurs online, offering scalability and efficiency compared to traditional methods.

### Sampling Techniques

#### Stratified Sampling

Stratified sampling ensures proportional representation of subgroups based on demographic data from the U.S. Census Bureau and voter registration databases. This approach minimizes sampling variability and improves the precision of population estimates [@Lohr2021]. Subgroup analyses, such as examining rural voting patterns or income brackets, are possible due to this method.

#### Sample Matching

Sample matching enhances representativeness by selecting respondents from a pool based on predefined demographic benchmarks. The CCES matches respondents to a target sample derived from voter registration data, reducing biases associated with convenience sampling [@Rivers2006].

#### Weighting

Post-stratification weights correct deviations between the survey sample and the target population. Iterative proportional fitting adjusts for age, gender, race, and geographic imbalances [@Gelman2007]. Weighting ensures the dataset reflects national trends, accounting for differences in response rates among demographic groups.

### Observational Data and Challenges

#### Strengths of Observational Surveys

Observational surveys like the CCES provide data on real-world voter behavior across diverse populations. The CCES’s large sample size, exceeding 61,000 respondents, allows detailed analyses of interactions between income, employment, and geography.

#### Limitations

1. **Nonresponse Bias**: Underrepresentation of certain groups, such as younger or less-educated individuals, skews results.
2. **Self-Reporting Bias**: Respondents may misreport voting behavior or demographic details due to social desirability or recall errors [@Ansolabehere2012].
3. **Cross-Sectional Nature**: The CCES captures data at specific points in time, limiting its ability to assess changes over time.
4. **Internet Access Disparities**: Online surveys may exclude populations with limited internet access, such as older or rural voters.

### Comparisons with Other Surveys

#### American National Election Studies (ANES)

The ANES combines face-to-face interviews with online surveys. Its smaller sample size limits subgroup analyses, but its detailed questions on political efficacy and ideology complement the CCES’s broader demographic focus [@Berinsky2014].

#### Pew Research Center Surveys

Pew Research surveys focus on shorter questionnaires tracking public opinion trends. While useful for snapshots, the CCES’s larger sample size and detailed questions better support modeling relationships between variables like income, employment, and location [@Pew2020].

### Methodological Best Practices

1. **Hybrid Sampling Methods**: Combining stratified sampling with other methods, such as online panel recruitment, improves representativeness.
2. **Enhanced Weighting Techniques**: Machine learning in weighting processes can reduce biases among hard-to-reach groups.
3. **Longitudinal Components**: Tracking individuals over time allows analysis of how voter behavior changes with events.
4. **Integration of Administrative Data**: Linking survey responses to administrative records, such as tax data, improves accuracy and reliability.

### Future Directions

To address challenges, future surveys like the CCES could adopt innovations such as:

- **Adaptive Sampling**: Adjusting strategies during data collection improves coverage of underrepresented groups.
- **Qualitative Data**: Including open-ended questions provides deeper understanding of voter motivations.
- **Non-Linear Models**: Bayesian hierarchical models improve estimation of subgroup effects, particularly for small populations.
- **Mobile Platforms**: Mobile-friendly surveys increase participation among younger and low-income groups, addressing access disparities.

These enhancements will improve survey accuracy and better capture the complexity of voter behavior.

\newpage

# References